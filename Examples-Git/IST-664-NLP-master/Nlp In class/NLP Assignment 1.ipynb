{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycorpus = PlaintextCorpusReader('.', '.*\\.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext= mycorpus.raw('wiki.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mytokens = nltk.word_tokenize(mytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(mytext, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "braw = soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytokens = nltk.word_tokenize(braw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Use all lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "mywords = [w.lower( ) for w in mytokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Removing punctuations from lower-case tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_filter(w):\n",
    "  # pattern to match word of non-alphabetical characters\n",
    "    pattern = re.compile('^[^a-z]+$')\n",
    "    if (pattern.match(w)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphamywords=[w for w in mywords if not alpha_filter(w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'just',\n",
       " 'a',\n",
       " 'curriculum',\n",
       " 'vitae',\n",
       " 'and',\n",
       " 'wp',\n",
       " 'linkfarm',\n",
       " 'for',\n",
       " 'a',\n",
       " 'non-notable',\n",
       " 'businessperson',\n",
       " 'and',\n",
       " 'that',\n",
       " \"'s\",\n",
       " 'all',\n",
       " 'the',\n",
       " 'article',\n",
       " 'has',\n",
       " 'ever',\n",
       " 'been',\n",
       " 'it',\n",
       " 'appears',\n",
       " 'the',\n",
       " 'subject',\n",
       " 'of',\n",
       " 'the',\n",
       " 'article',\n",
       " 'has',\n",
       " 'personally',\n",
       " 'contributed',\n",
       " 'much',\n",
       " 'of',\n",
       " 'the',\n",
       " 'material.',\n",
       " 'i',\n",
       " 'completely',\n",
       " 'agree',\n",
       " 'with',\n",
       " 'ivanvector',\n",
       " 'and',\n",
       " 'i',\n",
       " 'apologize',\n",
       " 'for',\n",
       " 'forgetting',\n",
       " 'to',\n",
       " 'mention',\n",
       " 'the',\n",
       " 'reason']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphamywords[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoppedmywords=[w for w in alphamywords if not w in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['curriculum',\n",
       " 'vitae',\n",
       " 'wp',\n",
       " 'linkfarm',\n",
       " 'non-notable',\n",
       " 'businessperson',\n",
       " \"'s\",\n",
       " 'article',\n",
       " 'ever',\n",
       " 'appears',\n",
       " 'subject',\n",
       " 'article',\n",
       " 'personally',\n",
       " 'contributed',\n",
       " 'much',\n",
       " 'material.',\n",
       " 'completely',\n",
       " 'agree',\n",
       " 'ivanvector',\n",
       " 'apologize',\n",
       " 'forgetting',\n",
       " 'mention',\n",
       " 'reason',\n",
       " 'felt',\n",
       " 'need',\n",
       " 'nominate',\n",
       " 'article',\n",
       " 'deletion',\n",
       " 'nominated',\n",
       " 'concrete',\n",
       " 'objective',\n",
       " 'sources',\n",
       " 'mentioned',\n",
       " 'seems',\n",
       " 'subject',\n",
       " 'contributed',\n",
       " 'extensively',\n",
       " 'article',\n",
       " 'question',\n",
       " 'notability',\n",
       " 'subject',\n",
       " 'seems',\n",
       " 'like',\n",
       " 'promotion/resume',\n",
       " 'article',\n",
       " 'ivanvector',\n",
       " 'also',\n",
       " 'mentioned.',\n",
       " 'fails',\n",
       " 'wp']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoppedmywords[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see words like /a, s, wp which we should add to list of stopwords. But lets find the 50 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. 50 most common words(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist=nltk.FreqDist(stoppedmywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdisttop=fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article 95713 0.012021094469326948\n",
      "wp 89720 0.011268402367369259\n",
      "'s 54509 0.00684606937854359\n",
      "sources 53579 0.006729265831935773\n",
      "n't 46690 0.005864040420558077\n",
      "notability 43464 0.005458870268561496\n",
      "notable 37705 0.00473556744607287\n",
      "coverage 31552 0.003962780110290179\n",
      "new 31264 0.003926608689405177\n",
      "please 27492 0.003452863551980781\n",
      "per 26943 0.0033839117809187466\n",
      "add 26506 0.003329026673534213\n",
      "one 26173 0.0032872034681359296\n",
      "comments 26048 0.0032715040667101476\n",
      "thanks 25611 0.003216618959325614\n",
      "notice 25134 0.00315671004348483\n",
      "reliable 23584 0.002962037465805134\n",
      "wikipedia 23015 0.0028905737905149742\n",
      "articles 22389 0.002811951188174658\n",
      "would 21531 0.0027041904967880907\n",
      "gng 21041 0.0026426488431990254\n",
      "fails 19121 0.002401506037299015\n",
      "subject 17533 0.002202060841585881\n",
      "also 17155 0.0021545858516743162\n",
      "page 16548 0.0020783495583507187\n",
      "find 15997 0.002009146596865872\n",
      "see 14935 0.0018757644823524284\n",
      "significant 14814 0.0018605674617722715\n",
      "list 14708 0.0018472543693632084\n",
      "like 13826 0.001736479392902891\n",
      "independent 13148 0.0016513258395694495\n",
      "enough 13111 0.0016466788167474181\n",
      "even 13107 0.001646176435901793\n",
      "could 12349 0.0015509752656558513\n",
      "source 12134 0.0015239722952035063\n",
      "seems 11644 0.001462430641614441\n",
      "afd 11202 0.0014069175581728761\n",
      "meet 11155 0.001401014583236782\n",
      "deletion 11072 0.0013905901806900629\n",
      "think 10946 0.0013747651840528745\n",
      "references 10793 0.0013555491167077174\n",
      "delete 10044 0.001261478303364432\n",
      "may 9640 0.0012107378379563047\n",
      "news 9484 0.001191144984976929\n",
      "found 9443 0.0011859955813092722\n",
      "'m 9027 0.0011337479733642699\n",
      "non-notable 8903 0.0011181741671498942\n",
      "nothing 8556 0.0010745926287919236\n",
      "google 8500 0.0010675592969531732\n",
      "two 8490 0.0010663033448391106\n"
     ]
    }
   ],
   "source": [
    "for item in fdisttop:\n",
    "    print(item[0],item[1],item[1]/len(mytext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding to the list of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.extend((\"/a\",\"wp\",\"/b\",\"'s\",\"b\",\"n't\",\"p\",\"/i\",\"dd\",\"/dd\",\"br\",\"q=\",\"/li\",\"rs\",\"li\",\"'m\",\"afd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Remove manually added stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoppedmywords=[w for w in alphamywords if not w in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article 95713 0.001090561074433901\n",
      "sources 53579 0.0006104831298475023\n",
      "notability 43464 0.0004952320639745393\n",
      "notable 37705 0.0004296135876164182\n",
      "coverage 31552 0.0003595058458154947\n",
      "new 31264 0.0003562243522938523\n",
      "please 27492 0.0003132459024201186\n",
      "per 26943 0.00030699055539448766\n",
      "add 26506 0.00030201134473838436\n",
      "one 26173 0.0002982171178539853\n",
      "comments 26048 0.0002967928585129946\n",
      "thanks 25611 0.0002918136478568913\n",
      "notice 25134 0.00028637867421167103\n",
      "reliable 23584 0.000268717858383387\n",
      "wikipedia 23015 0.0002622346298631976\n",
      "articles 22389 0.00025510193908351644\n",
      "would 21531 0.0002453258229669567\n",
      "gng 21041 0.00023974272635027334\n",
      "fails 19121 0.00021786610287265703\n",
      "subject 17533 0.00019977231220471187\n",
      "also 17155 0.00019546535195755617\n",
      "page 16548 0.00018854914859770558\n",
      "find 15997 0.00018227101342261883\n",
      "see 14935 0.0001701705060615623\n",
      "significant 14814 0.00016879182301948335\n",
      "list 14708 0.0001675840510983233\n",
      "like 13826 0.0001575344771882933\n",
      "independent 13148 0.00014980929452276004\n",
      "enough 13111 0.0001493877137578268\n",
      "even 13107 0.0001493421374589151\n",
      "could 12349 0.00014070542881514783\n",
      "source 12134 0.00013825570274864391\n",
      "seems 11644 0.0001326726061319606\n",
      "meet 11155 0.00012710090359000517\n",
      "deletion 11072 0.0001261551953875874\n",
      "think 10946 0.00012471954197186883\n",
      "references 10793 0.00012297624853849627\n",
      "delete 10044 0.00011444208656728033\n",
      "may 9640 0.00010983888037719857\n",
      "news 9484 0.00010806140471964223\n",
      "found 9443 0.0001075942476557973\n",
      "non-notable 8903 0.00010144144730271773\n",
      "nothing 8556 9.748770337212768e-05\n",
      "google 8500 9.684963518736388e-05\n",
      "two 8490 9.673569444008463e-05\n",
      "search 8160 9.297564977986933e-05\n",
      "information 8092 9.220085269837041e-05\n",
      "keep 8048 9.169951341034171e-05\n",
      "books 7791 8.877123620526494e-05\n",
      "evidence 7744 8.823571469305246e-05\n"
     ]
    }
   ],
   "source": [
    "fdist=nltk.FreqDist(stoppedmywords)\n",
    "fdisttop=fdist.most_common(50)\n",
    "for item in fdisttop:\n",
    "    print(item[0],item[1],item[1]/len(mytext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  top 50 bigrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = BigramCollocationFinder.from_words(stoppedmywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored = finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('please', 'add'), 0.005764611157844224)\n",
      "(('add', 'new'), 0.005755127549786572)\n",
      "(('new', 'comments'), 0.005751808286966393)\n",
      "(('comments', 'notice'), 0.005750859926160628)\n",
      "(('notice', 'thanks'), 0.00574943738495198)\n",
      "(('reliable', 'sources'), 0.0030127051897148372)\n",
      "(('significant', 'coverage'), 0.0018196672960621215)\n",
      "(('non-admin', 'closure'), 0.0014099754279715225)\n",
      "(('thanks', 'please'), 0.0013829471450072122)\n",
      "(('fails', 'gng'), 0.0013125313551791407)\n",
      "(('wikipedia', 'articles'), 0.001002654461895337)\n",
      "(('coverage', 'reliable'), 0.000959504045233017)\n",
      "(('per', 'nom'), 0.0007288152792306138)\n",
      "(('establish', 'notability'), 0.0006930146588129747)\n",
      "(('find', 'sources'), 0.0006925404784100921)\n",
      "(('books', 'scholar'), 0.0006244955905964336)\n",
      "(('newspapers', 'books'), 0.0006211763277762551)\n",
      "(('scholar', 'highbeam'), 0.0006171457943517527)\n",
      "(('highbeam', 'jstor'), 0.0006166716139488701)\n",
      "(('independent', 'reliable'), 0.0006078992764955413)\n",
      "(('could', 'find'), 0.0006052912842796868)\n",
      "(('notability', 'guidelines'), 0.0005661714010418692)\n",
      "(('independent', 'sources'), 0.0005647488598332212)\n",
      "(('reliable', 'source'), 0.0005621408676173668)\n",
      "(('comment', 'added'), 0.0005519459889553901)\n",
      "(('unsigned', 'comment'), 0.0005476783653294463)\n",
      "(('secondary', 'sources'), 0.0005457816437179157)\n",
      "(('preceding', 'unsigned'), 0.0005453074633150331)\n",
      "(('evidence', 'notability'), 0.0005329787728400846)\n",
      "(('ca', 'find'), 0.0005178049999478402)\n",
      "(('notable', 'enough'), 0.0005166195489406336)\n",
      "(('meet', 'gng'), 0.0005144857371276617)\n",
      "(('talk', 'page'), 0.00048105601872443574)\n",
      "(('looks', 'like'), 0.0004665935164365153)\n",
      "(('jstor', 'free'), 0.00044952302193274036)\n",
      "(('free', 'images'), 0.00044928593173129905)\n",
      "(('images', 'wikipedia'), 0.00044928593173129905)\n",
      "(('news', 'newspapers'), 0.0004485746611269751)\n",
      "(('wikipedia', 'library'), 0.00044691502971688584)\n",
      "(('thanks', 'per'), 0.00044217322568805946)\n",
      "(('google', 'search'), 0.0004258140017886085)\n",
      "(('closure', 'non-admin'), 0.00042368018997563663)\n",
      "(('talk', 'contribs'), 0.00041514494272374916)\n",
      "(('general', 'notability'), 0.0004073209660761856)\n",
      "(('non', 'notable'), 0.0003992598992271808)\n",
      "(('reliable', 'independent'), 0.00035990292578792185)\n",
      "(('original', 'research'), 0.0003537385805504476)\n",
      "(('sources', 'article'), 0.0003527902197446823)\n",
      "(('played', 'fully'), 0.00035231603934179965)\n",
      "(('meet', 'notability'), 0.0003506564079317104)\n"
     ]
    }
   ],
   "source": [
    "for bscore in scored[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigrams by mi scores(frq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder2 = BigramCollocationFinder.from_words(stoppedmywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder2.apply_freq_filter(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored = finder2.score_ngrams(bigram_measures.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('burr', 'steers'), 19.68613252954993)\n",
      "(('helsingin', 'sanomat'), 19.68613252954993)\n",
      "(('hemorrhagic', 'conjunctivitis'), 19.68613252954993)\n",
      "(('inã©s', 'rodena'), 19.68613252954993)\n",
      "(('khyber', 'pakhtunkhwa'), 19.68613252954993)\n",
      "(('manadel', 'al-jamadi'), 19.68613252954993)\n",
      "(('mys', '721tx'), 19.68613252954993)\n",
      "(('pell', 'mell'), 19.68613252954993)\n",
      "(('phnom', 'penh'), 19.68613252954993)\n",
      "(('putroe', 'neng'), 19.68613252954993)\n",
      "(('rot-weiãÿ', 'oberhausen'), 19.68613252954993)\n",
      "(('schwã¤bisch', 'gmã¼nd'), 19.68613252954993)\n",
      "(('sunanda', 'pushkar'), 19.68613252954993)\n",
      "(('super-god', 'masterforce'), 19.68613252954993)\n",
      "(('vis-ã', '-vis'), 19.68613252954993)\n",
      "(('ashleigh', 'lollie'), 19.423098123716134)\n",
      "(('beent', 'agged'), 19.423098123716134)\n",
      "(('deletion/anshei', 'sfard'), 19.423098123716134)\n",
      "(('deletion/beth', 'hamedrosh'), 19.423098123716134)\n",
      "(('dudel250', 'chatprod'), 19.423098123716134)\n",
      "(('energy-safety', 'energy-economy'), 19.423098123716134)\n",
      "(('giro', \"d'italia\"), 19.423098123716134)\n",
      "(('hamedrosh', 'hagodol-beth'), 19.423098123716134)\n",
      "(('lorem', 'ipsum'), 19.423098123716134)\n",
      "(('m.j.', 'ramanan'), 19.423098123716134)\n",
      "(('margarita', 'martirena'), 19.423098123716134)\n",
      "(('mong', 'kok'), 19.423098123716134)\n",
      "(('movers', 'shakers'), 19.423098123716134)\n",
      "(('rls=org.mozilla', 'en-us'), 19.423098123716134)\n",
      "(('suhas', 'gopinath'), 19.423098123716134)\n",
      "(('ulrike', 'ottinger'), 19.423098123716134)\n",
      "(('vitalik', 'buterin'), 19.423098123716134)\n",
      "(('xhulio', 'joka'), 19.423098123716134)\n",
      "(('abdulhadi', 'najjar'), 19.200705702379686)\n",
      "(('aqueduct', 'racetrack'), 19.200705702379686)\n",
      "(('chal', 'jhoothey'), 19.200705702379686)\n",
      "(('charles_manson', 'tate_murders'), 19.200705702379686)\n",
      "(('deletion/tessa', 'campanelli'), 19.200705702379686)\n",
      "(('diante', 'trono'), 19.200705702379686)\n",
      "(('guo', 'dongli'), 19.200705702379686)\n",
      "(('hidy', 'ochiai'), 19.200705702379686)\n",
      "(('marlene', 'dietrich'), 19.200705702379686)\n",
      "(('mushtaq', 'pahalgami'), 19.200705702379686)\n",
      "(('officeâ€\\x9dwp', 'politition'), 19.200705702379686)\n",
      "(('option=com_content', 'view=article'), 19.200705702379686)\n",
      "(('politition', 'states-'), 19.200705702379686)\n",
      "(('rowman', 'littlefield'), 19.200705702379686)\n",
      "(('sadman', 'sakibzz'), 19.200705702379686)\n",
      "(('satish', 'rajwade'), 19.200705702379686)\n",
      "(('sebalu', 'lule'), 19.200705702379686)\n"
     ]
    }
   ],
   "source": [
    "for bscore in scored[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import nps_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatroom = nps_chat.posts('10-19-20s_706posts.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'want',\n",
       " 'hot',\n",
       " 'pics',\n",
       " 'of',\n",
       " 'a',\n",
       " 'female',\n",
       " ',',\n",
       " 'I',\n",
       " 'can',\n",
       " 'look',\n",
       " 'in',\n",
       " 'a',\n",
       " 'mirror',\n",
       " '.']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatroom[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "chattext=nps_chat.raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1 = BeautifulSoup(chattext, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "braw1 = soup1.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytokens1 = nltk.word_tokenize(braw1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "mywords1 = [w.lower( ) for w in mytokens1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphamywords1=[w for w in mywords1 if not alpha_filter(w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords1 = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoppedmywords1=[w for w in alphamywords1 if not w in stopwords1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['im',\n",
       " 'left',\n",
       " 'gay',\n",
       " 'name',\n",
       " 'p',\n",
       " 'part',\n",
       " 'hey',\n",
       " 'everyone',\n",
       " 'ah',\n",
       " 'well',\n",
       " 'nick',\n",
       " ':10-19-20suser7',\n",
       " '10-19-20suser7',\n",
       " 'gay',\n",
       " 'name',\n",
       " '.action',\n",
       " 'gives',\n",
       " '10-19-20suser121',\n",
       " 'golf',\n",
       " 'clap',\n",
       " 'join',\n",
       " 'hi',\n",
       " '10-19-20suser59',\n",
       " 'm/',\n",
       " 'ky',\n",
       " 'women',\n",
       " 'nice',\n",
       " 'please',\n",
       " 'pm',\n",
       " 'join',\n",
       " 'part',\n",
       " 'ya',\n",
       " 'go',\n",
       " '10-19-20suser7',\n",
       " \"n't\",\n",
       " 'golf',\n",
       " 'clap',\n",
       " 'fuck',\n",
       " '10-19-20suser121',\n",
       " 'whats',\n",
       " 'everyone',\n",
       " 'part',\n",
       " 'part',\n",
       " \"'ll\",\n",
       " 'thunder',\n",
       " 'clap',\n",
       " 'ass',\n",
       " 'part',\n",
       " 'dont',\n",
       " 'even']"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoppedmywords1[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist1=nltk.FreqDist(stoppedmywords1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdisttop1=fdist1.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 1022 0.000397889550221292\n",
      "join 1021 0.0003975002258081596\n",
      "lol 768 0.00029900114928566756\n",
      "hi 656 0.00025539681501484106\n",
      ".action 346 0.00013470624694380336\n",
      "hey 289 0.00011251475539525771\n",
      "'s 204 7.942218027900544e-05\n",
      "u 203 7.903285586587307e-05\n",
      "like 158 6.151325727491599e-05\n",
      "pm 149 5.800933755672457e-05\n",
      "na 147 5.723068873045981e-05\n",
      "chat 145 5.645203990419505e-05\n",
      "im 143 5.567339107793029e-05\n",
      "n't 142 5.528406666479791e-05\n",
      "'m 133 5.178014694660649e-05\n",
      "good 129 5.0222849294076975e-05\n",
      "lmao 122 4.7497578402150315e-05\n",
      "wan 110 4.2825685444561764e-05\n",
      "know 103 4.0100414552635105e-05\n",
      "get 103 4.0100414552635105e-05\n",
      "room 102 3.971109013950272e-05\n",
      "ok 101 3.9321765726370344e-05\n",
      "ya 98 3.8153792486973206e-05\n",
      "wb 96 3.7375143660708445e-05\n",
      "hello 91 3.5428521595046546e-05\n",
      "one 90 3.503919718191417e-05\n",
      "oh 89 3.4649872768781786e-05\n",
      "well 86 3.348189952938465e-05\n",
      "hiya 84 3.270325070311989e-05\n",
      "yes 83 3.231392628998751e-05\n",
      "yeah 83 3.231392628998751e-05\n",
      "back 79 3.0756628637457995e-05\n",
      "got 79 3.0756628637457995e-05\n",
      "go 77 2.9977979811193234e-05\n",
      "dont 76 2.9588655398060854e-05\n",
      "see 76 2.9588655398060854e-05\n",
      "want 70 2.7252708919266575e-05\n",
      "ty 70 2.7252708919266575e-05\n",
      "everyone 66 2.5695411266737056e-05\n",
      "love 64 2.4916762440472296e-05\n",
      "anyone 60 2.3359464787942777e-05\n",
      "guys 59 2.29701403748104e-05\n",
      "talk 57 2.219149154854564e-05\n",
      "would 55 2.1412842722280882e-05\n",
      "right 55 2.1412842722280882e-05\n",
      "think 54 2.10235183091485e-05\n",
      "nice 53 2.063419389601612e-05\n",
      "thanks 53 2.063419389601612e-05\n",
      "girls 51 1.985554506975136e-05\n",
      "time 50 1.9466220656618983e-05\n"
     ]
    }
   ],
   "source": [
    "for item in fdisttop1:\n",
    "    print(item[0],item[1],item[1]/len(chattext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords1.extend((\"/a\",\"wp\",\"/b\",\"'s\",\"b\",\"n't\",\"p\",\"/i\",\"dd\",\"/dd\",\"br\",\"q=\",\"/li\",\"rs\",\"li\",\"'m\",\"afd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoppedmywords1=[w for w in alphamywords1 if not w in stopwords1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 1022 0.000397889550221292\n",
      "join 1021 0.0003975002258081596\n",
      "lol 768 0.00029900114928566756\n",
      "hi 656 0.00025539681501484106\n",
      ".action 346 0.00013470624694380336\n",
      "hey 289 0.00011251475539525771\n",
      "u 203 7.903285586587307e-05\n",
      "like 158 6.151325727491599e-05\n",
      "pm 149 5.800933755672457e-05\n",
      "na 147 5.723068873045981e-05\n",
      "chat 145 5.645203990419505e-05\n",
      "im 143 5.567339107793029e-05\n",
      "good 129 5.0222849294076975e-05\n",
      "lmao 122 4.7497578402150315e-05\n",
      "wan 110 4.2825685444561764e-05\n",
      "know 103 4.0100414552635105e-05\n",
      "get 103 4.0100414552635105e-05\n",
      "room 102 3.971109013950272e-05\n",
      "ok 101 3.9321765726370344e-05\n",
      "ya 98 3.8153792486973206e-05\n",
      "wb 96 3.7375143660708445e-05\n",
      "hello 91 3.5428521595046546e-05\n",
      "one 90 3.503919718191417e-05\n",
      "oh 89 3.4649872768781786e-05\n",
      "well 86 3.348189952938465e-05\n",
      "hiya 84 3.270325070311989e-05\n",
      "yes 83 3.231392628998751e-05\n",
      "yeah 83 3.231392628998751e-05\n",
      "back 79 3.0756628637457995e-05\n",
      "got 79 3.0756628637457995e-05\n",
      "go 77 2.9977979811193234e-05\n",
      "dont 76 2.9588655398060854e-05\n",
      "see 76 2.9588655398060854e-05\n",
      "want 70 2.7252708919266575e-05\n",
      "ty 70 2.7252708919266575e-05\n",
      "everyone 66 2.5695411266737056e-05\n",
      "love 64 2.4916762440472296e-05\n",
      "anyone 60 2.3359464787942777e-05\n",
      "guys 59 2.29701403748104e-05\n",
      "talk 57 2.219149154854564e-05\n",
      "would 55 2.1412842722280882e-05\n",
      "right 55 2.1412842722280882e-05\n",
      "think 54 2.10235183091485e-05\n",
      "nice 53 2.063419389601612e-05\n",
      "thanks 53 2.063419389601612e-05\n",
      "girls 51 1.985554506975136e-05\n",
      "time 50 1.9466220656618983e-05\n",
      "11-09-40suser18 48 1.8687571830354223e-05\n",
      "bye 46 1.7908923004089465e-05\n",
      "haha 45 1.7519598590957085e-05\n"
     ]
    }
   ],
   "source": [
    "fdist1=nltk.FreqDist(stoppedmywords1)\n",
    "fdisttop1=fdist1.most_common(50)\n",
    "for item in fdisttop1:\n",
    "    print(item[0],item[1],item[1]/len(chattext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures1 = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder10 = BigramCollocationFinder.from_words(stoppedmywords1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored10 = finder10.score_ngrams(bigram_measures1.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('part', 'join'), 0.0076560659599528855)\n",
      "(('join', 'part'), 0.005378877110325873)\n",
      "(('part', 'part'), 0.004789948959560267)\n",
      "(('wan', 'na'), 0.0043188064389477815)\n",
      "(('join', 'join'), 0.004279544562230075)\n",
      "(('na', 'chat'), 0.002355712603062426)\n",
      "(('join', 'hi'), 0.0021201413427561835)\n",
      "(('lol', 'lol'), 0.0016882606988614056)\n",
      "(('lol', 'join'), 0.0016097369454259915)\n",
      "(('part', 'hi'), 0.0016097369454259915)\n",
      "(('part', 'lol'), 0.0016097369454259915)\n",
      "(('lol', 'hi'), 0.001531213191990577)\n",
      "(('lol', 'part'), 0.001531213191990577)\n",
      "(('gon', 'na'), 0.001452689438555163)\n",
      "(('join', 'lol'), 0.0013741656851197488)\n",
      "(('join', '.action'), 0.0013349038084020416)\n",
      "(('mode', '14-19teens'), 0.001099332548095799)\n",
      "(('part', '.action'), 0.0010208087946603848)\n",
      "(('part', 'hey'), 0.0009422850412249705)\n",
      "(('join', 'hey'), 0.0009030231645072635)\n",
      "(('pm', 'u'), 0.0009030231645072635)\n",
      "(('14-19teens', '+o'), 0.0007852375343541421)\n",
      "(('.action', 'watches'), 0.0007459756576364351)\n",
      "(('18/m', 'pm'), 0.0007459756576364351)\n",
      "(('chat', 'pm'), 0.0007067137809187279)\n",
      "(('want', 'chat'), 0.0007067137809187279)\n",
      "(('guys', 'wan'), 0.0006674519042010208)\n",
      "(('lol', 'hey'), 0.0006281900274833137)\n",
      "(('tryin', 'chat'), 0.0006281900274833137)\n",
      "(('u', 'tryin'), 0.0006281900274833137)\n",
      "(('anyone', 'wan'), 0.0005889281507656066)\n",
      "(('r', 'u'), 0.0005889281507656066)\n",
      "(('dont', 'know'), 0.0005496662740478995)\n",
      "(('hi', 'everyone'), 0.0005496662740478995)\n",
      "(('join', 'wb'), 0.0005104043973301924)\n",
      "(('lol', '.action'), 0.0005104043973301924)\n",
      "(('.action', 'sits'), 0.0004711425206124853)\n",
      "(('got', 'ta'), 0.0004711425206124853)\n",
      "(('join', 'lmao'), 0.0004711425206124853)\n",
      "(('join', 'well'), 0.0004711425206124853)\n",
      "(('la', 'la'), 0.0004711425206124853)\n",
      "(('10-26-teensuser54', '10-26-teensuser54'), 0.00043188064389477815)\n",
      "(('girls', 'wan'), 0.00043188064389477815)\n",
      "(('hi', '10-19-40suser30'), 0.00043188064389477815)\n",
      "(('na', 'talk'), 0.00043188064389477815)\n",
      "(('see', 'ya'), 0.00043188064389477815)\n",
      "(('.13cute.-ass', 'mp3'), 0.00039261876717707107)\n",
      "(('.action', '.liam'), 0.00039261876717707107)\n",
      "(('.action', 'listening'), 0.00039261876717707107)\n",
      "(('.action', 'song'), 0.00039261876717707107)\n"
     ]
    }
   ],
   "source": [
    "for bscore in scored10[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder20 = BigramCollocationFinder.from_words(stoppedmywords1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder20.apply_freq_filter(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored20 = finder20.score_ngrams(bigram_measures1.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('lez', 'gurls'), 11.636511339161558)\n",
      "(('gently', 'kisses'), 11.466586337719246)\n",
      "(('bi', 'lez'), 11.314583244274196)\n",
      "(('.13cute.-ass', 'mp3'), 11.314583244274194)\n",
      "(('.liam', '.13cute.-ass'), 11.314583244274194)\n",
      "(('times..', '.this'), 11.314583244274194)\n",
      "(('fingers', 'thru'), 11.20355193188545)\n",
      "(('neck', 'compliments'), 11.20355193188545)\n",
      "(('bit', 'large'), 11.0515488384404)\n",
      "(('played', 'times..'), 11.0515488384404)\n",
      "(('ice', 'cream'), 10.914045314690465)\n",
      "(('runs', 'fingers'), 10.788514432606608)\n",
      "(('eyes', 'gently'), 10.636511339161558)\n",
      "(('.9lime', 'player'), 10.549048497911217)\n",
      "(('mp3', 'player'), 10.549048497911217)\n",
      "(('player', '.song'), 10.549048497911217)\n",
      "(('closes', 'eyes'), 10.373476933327764)\n",
      "(('minutes', 'ago'), 10.314583244274193)\n",
      "(('hair', 'closes'), 10.286014092077425)\n",
      "(('minutes/seconds', 'music'), 10.112949383104544)\n",
      "(('n', 'e'), 10.021801495046347)\n",
      "((':10-26-teensuser122', '10-26-teensuser122'), 9.992655149386833)\n",
      "(('talkin', 'bout'), 9.788514432606608)\n",
      "(('la', 'la'), 9.725618812995542)\n",
      "(('leave', 'alone'), 9.701051591356268)\n",
      "((':10-26-teensuser54', '10-26-teensuser54'), 9.592117219803104)\n",
      "(('.this', 'song'), 9.466586337719244)\n",
      "(('player', 'listening'), 9.347414636741567)\n",
      "(('14-19teens', '+o'), 9.296661336276932)\n",
      "(('mode', '40splus'), 9.278959334543472)\n",
      "(('busy', 'busy'), 9.221473839882712)\n",
      "(('song', 'played'), 9.20355193188545)\n",
      "(('mode', '14-19teens'), 9.179423660992562)\n",
      "(('around', 'bit'), 8.849914977270751)\n",
      "(('10-26-teensuser122', '10-26-teensuser122'), 8.518723961054421)\n",
      "(('welcome', 'talkcity_adults'), 8.292708744651433)\n",
      "(('14-19teens', '-o'), 8.085764553778315)\n",
      "(('thru', 'back'), 8.06969618515066)\n",
      "(('+o', '10-26-teensuser54'), 8.007154719081948)\n",
      "(('10-26-teensuser54', '10-26-teensuser54'), 8.007154719081948)\n",
      "(('mode', 'talkcity_adults'), 7.998851415350741)\n",
      "(('main', 'room'), 7.964085997190061)\n",
      "(('got', 'ta'), 7.830230250455269)\n",
      "(('10-26-teensuser122', 'mode'), 7.805028146211061)\n",
      "(('last', 'night'), 7.507228322216591)\n",
      "(('females', 'want'), 7.507228322216589)\n",
      "(('last', 'seen'), 7.466586337719246)\n",
      "(('long', 'time'), 7.456602249146622)\n",
      "(('gon', 'na'), 7.4368389943251945)\n",
      "(('wan', 'na'), 7.436838994325193)\n"
     ]
    }
   ],
   "source": [
    "for bscore in scored20[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "puzzle_letters = nltk.FreqDist('egbdafkjlmorcnst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "obligatory=\"m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = nltk.corpus.words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abdomen',\n",
       " 'abelmosk',\n",
       " 'acneform',\n",
       " 'almond',\n",
       " 'almoner',\n",
       " 'almost',\n",
       " 'ambler',\n",
       " 'ambrose',\n",
       " 'amelcorn',\n",
       " 'amends',\n",
       " 'amlong',\n",
       " 'amober',\n",
       " 'amongst',\n",
       " 'amoret',\n",
       " 'angeldom',\n",
       " 'angstrom',\n",
       " 'antdom',\n",
       " 'armbone',\n",
       " 'armlet',\n",
       " 'asmoke',\n",
       " 'asmolder',\n",
       " 'atomerg',\n",
       " 'backmost',\n",
       " 'bakerdom',\n",
       " 'bankerdom',\n",
       " 'barksome',\n",
       " 'barmote',\n",
       " 'barsom',\n",
       " 'beardom',\n",
       " 'beastdom',\n",
       " 'becalm',\n",
       " 'beclamor',\n",
       " 'becram',\n",
       " 'bedamn',\n",
       " 'bedlam',\n",
       " 'bedman',\n",
       " 'befoam',\n",
       " 'beldam',\n",
       " 'beloam',\n",
       " 'beltman',\n",
       " 'bemask',\n",
       " 'bemoan',\n",
       " 'bemoat',\n",
       " 'bemock',\n",
       " 'bemolt',\n",
       " 'benmost',\n",
       " 'bergamot',\n",
       " 'bestorm',\n",
       " 'blamed',\n",
       " 'blamer',\n",
       " 'blastoderm',\n",
       " 'blockman',\n",
       " 'bogman',\n",
       " 'boltmaker',\n",
       " 'bregma',\n",
       " 'bromal',\n",
       " 'bromate',\n",
       " 'calmer',\n",
       " 'camber',\n",
       " 'cambrel',\n",
       " 'camlet',\n",
       " 'camstone',\n",
       " 'carmot',\n",
       " 'catdom',\n",
       " 'cembalo',\n",
       " 'ceroma',\n",
       " 'clamber',\n",
       " 'clamer',\n",
       " 'clamor',\n",
       " 'clerkdom',\n",
       " 'cloamen',\n",
       " 'cloamer',\n",
       " 'clogmaker',\n",
       " 'clomben',\n",
       " 'coagment',\n",
       " 'cobleman',\n",
       " 'codman',\n",
       " 'cogman',\n",
       " 'cokeman',\n",
       " 'colmar',\n",
       " 'comaker',\n",
       " 'comart',\n",
       " 'comate',\n",
       " 'combat',\n",
       " 'combater',\n",
       " 'combed',\n",
       " 'comber',\n",
       " 'comble',\n",
       " 'comrade',\n",
       " 'conamed',\n",
       " 'cormel',\n",
       " 'cotman',\n",
       " 'crambe',\n",
       " 'cramble',\n",
       " 'crambo',\n",
       " 'daemon',\n",
       " 'dambose',\n",
       " 'damner',\n",
       " 'damsel',\n",
       " 'damson',\n",
       " 'darksome',\n",
       " 'deform',\n",
       " 'demark',\n",
       " 'demast',\n",
       " 'democrat',\n",
       " 'dermal',\n",
       " 'dermoblast',\n",
       " 'dermol',\n",
       " 'desman',\n",
       " 'desmon',\n",
       " 'dockman',\n",
       " 'dockmaster',\n",
       " 'dogman',\n",
       " 'dolesman',\n",
       " 'dolman',\n",
       " 'dolmen',\n",
       " 'doment',\n",
       " 'dormant',\n",
       " 'dreamt',\n",
       " 'earldom',\n",
       " 'embank',\n",
       " 'embargo',\n",
       " 'embark',\n",
       " 'enamor',\n",
       " 'endmost',\n",
       " 'engram',\n",
       " 'enjamb',\n",
       " 'enmask',\n",
       " 'entomb',\n",
       " 'escambron',\n",
       " 'estmark',\n",
       " 'fabledom',\n",
       " 'fadmonger',\n",
       " 'famble',\n",
       " 'fandom',\n",
       " 'farmost',\n",
       " 'femora',\n",
       " 'femoral',\n",
       " 'flamberg',\n",
       " 'flamed',\n",
       " 'flamen',\n",
       " 'flamenco',\n",
       " 'flamer',\n",
       " 'flatdom',\n",
       " 'flockman',\n",
       " 'flockmaster',\n",
       " 'flogmaster',\n",
       " 'flotsam',\n",
       " 'foamer',\n",
       " 'foeman',\n",
       " 'fogman',\n",
       " 'fogram',\n",
       " 'foment',\n",
       " 'foramen',\n",
       " 'foreman',\n",
       " 'foremast',\n",
       " 'forgeman',\n",
       " 'forkman',\n",
       " 'formable',\n",
       " 'formagen',\n",
       " 'formal',\n",
       " 'formant',\n",
       " 'format',\n",
       " 'formate',\n",
       " 'formed',\n",
       " 'formel',\n",
       " 'fotmal',\n",
       " 'fragment',\n",
       " 'framed',\n",
       " 'freakdom',\n",
       " 'frogman',\n",
       " 'gambeson',\n",
       " 'gambet',\n",
       " 'gamble',\n",
       " 'gambler',\n",
       " 'gambol',\n",
       " 'gambrel',\n",
       " 'gamont',\n",
       " 'garment',\n",
       " 'gemsbok',\n",
       " 'geomant',\n",
       " 'germal',\n",
       " 'german',\n",
       " 'germon',\n",
       " 'gladsome',\n",
       " 'gnomed',\n",
       " 'godmaker',\n",
       " 'gomart',\n",
       " 'gomeral',\n",
       " 'gormed',\n",
       " 'graftdom',\n",
       " 'jambone',\n",
       " 'jambstone',\n",
       " 'jarldom',\n",
       " 'jasmone',\n",
       " 'jermonal',\n",
       " 'jetsam',\n",
       " 'jobman',\n",
       " 'jobmaster',\n",
       " 'katmon',\n",
       " 'kerslam',\n",
       " 'lambent',\n",
       " 'lamber',\n",
       " 'lambert',\n",
       " 'lament',\n",
       " 'landstorm',\n",
       " 'larksome',\n",
       " 'leafdom',\n",
       " 'legman',\n",
       " 'lemnad',\n",
       " 'lockerman',\n",
       " 'lockman',\n",
       " 'lockram',\n",
       " 'locksman',\n",
       " 'lodesman',\n",
       " 'lodgeman',\n",
       " 'lodgment',\n",
       " 'loftman',\n",
       " 'loftsman',\n",
       " 'logman',\n",
       " 'lombard',\n",
       " 'loment',\n",
       " 'mackle',\n",
       " 'macled',\n",
       " 'macron',\n",
       " 'madstone',\n",
       " 'maestro',\n",
       " 'magnes',\n",
       " 'magnet',\n",
       " 'magneto',\n",
       " 'magnetod',\n",
       " 'malfed',\n",
       " 'malter',\n",
       " 'maltose',\n",
       " 'manbot',\n",
       " 'mandore',\n",
       " 'mandrel',\n",
       " 'mangel',\n",
       " 'manger',\n",
       " 'mangle',\n",
       " 'mangler',\n",
       " 'manlet',\n",
       " 'manred',\n",
       " 'mantel',\n",
       " 'manter',\n",
       " 'mantes',\n",
       " 'mantle',\n",
       " 'mantled',\n",
       " 'marble',\n",
       " 'marbled',\n",
       " 'marbles',\n",
       " 'marcel',\n",
       " 'marengo',\n",
       " 'margent',\n",
       " 'marked',\n",
       " 'market',\n",
       " 'marled',\n",
       " 'marlock',\n",
       " 'martel',\n",
       " 'marten',\n",
       " 'mascled',\n",
       " 'mascot',\n",
       " 'masked',\n",
       " 'masker',\n",
       " 'masoned',\n",
       " 'masoner',\n",
       " 'masted',\n",
       " 'master',\n",
       " 'matfelon',\n",
       " 'matron',\n",
       " 'medlar',\n",
       " 'megadont',\n",
       " 'megaron',\n",
       " 'megaton',\n",
       " 'megotalc',\n",
       " 'melano',\n",
       " 'melosa',\n",
       " 'melton',\n",
       " 'menald',\n",
       " 'menfolk',\n",
       " 'mensal',\n",
       " 'mental',\n",
       " 'mentor',\n",
       " 'mercal',\n",
       " 'merfold',\n",
       " 'merfolk',\n",
       " 'merlon',\n",
       " 'mescal',\n",
       " 'mesobar',\n",
       " 'mobster',\n",
       " 'mockable',\n",
       " 'mocker',\n",
       " 'modena',\n",
       " 'moderant',\n",
       " 'modern',\n",
       " 'modest',\n",
       " 'molder',\n",
       " 'molecast',\n",
       " 'molest',\n",
       " 'molten',\n",
       " 'molter',\n",
       " 'monase',\n",
       " 'monaster',\n",
       " 'moneral',\n",
       " 'monger',\n",
       " 'mongler',\n",
       " 'mongrel',\n",
       " 'mongst',\n",
       " 'monkcraft',\n",
       " 'monster',\n",
       " 'montage',\n",
       " 'morale',\n",
       " 'morals',\n",
       " 'morate',\n",
       " 'mordant',\n",
       " 'mordent',\n",
       " 'morgan',\n",
       " 'morgen',\n",
       " 'morned',\n",
       " 'morsal',\n",
       " 'morsel',\n",
       " 'mortal',\n",
       " 'mosker',\n",
       " 'nearmost',\n",
       " 'neckmold',\n",
       " 'nemoral',\n",
       " 'normal',\n",
       " 'normated',\n",
       " 'omental',\n",
       " 'oreman',\n",
       " 'orgasm',\n",
       " 'osmate',\n",
       " 'ostmark',\n",
       " 'radome',\n",
       " 'ramble',\n",
       " 'rambong',\n",
       " 'rament',\n",
       " 'ramose',\n",
       " 'ramson',\n",
       " 'randem',\n",
       " 'random',\n",
       " 'ransom',\n",
       " 'recomb',\n",
       " 'remand',\n",
       " 'remask',\n",
       " 'remast',\n",
       " 'remock',\n",
       " 'remold',\n",
       " 'retomb',\n",
       " 'rockman',\n",
       " 'rodman',\n",
       " 'rodsman',\n",
       " 'romance',\n",
       " 'salmon',\n",
       " 'salmonet',\n",
       " 'samlet',\n",
       " 'sarment',\n",
       " 'scamble',\n",
       " 'scambler',\n",
       " 'scamler',\n",
       " 'scleroma',\n",
       " 'scramble',\n",
       " 'scream',\n",
       " 'seamrog',\n",
       " 'seldom',\n",
       " 'selfdom',\n",
       " 'semblant',\n",
       " 'semola',\n",
       " 'serfdom',\n",
       " 'sermon',\n",
       " 'sjambok',\n",
       " 'smacker',\n",
       " 'smalter',\n",
       " 'smarten',\n",
       " 'smocker',\n",
       " 'smoked',\n",
       " 'smoker',\n",
       " 'smolder',\n",
       " 'socman',\n",
       " 'sokeman',\n",
       " 'solemn',\n",
       " 'somber',\n",
       " 'sombre',\n",
       " 'sorema',\n",
       " 'stagedom',\n",
       " 'stamen',\n",
       " 'stardom',\n",
       " 'stockman',\n",
       " 'storeman',\n",
       " 'stormable',\n",
       " 'stream',\n",
       " 'stroam',\n",
       " 'stroma',\n",
       " 'stromal',\n",
       " 'stromb',\n",
       " 'strome',\n",
       " 'tamber',\n",
       " 'tambor',\n",
       " 'tandem',\n",
       " 'tarsome',\n",
       " 'telamon',\n",
       " 'temblor',\n",
       " 'termon',\n",
       " 'tombac',\n",
       " 'tombal',\n",
       " 'tormen',\n",
       " 'transmold',\n",
       " 'transom',\n",
       " 'transomed',\n",
       " 'tromba',\n",
       " 'trombe',\n",
       " 'tsardom',\n",
       " 'almost',\n",
       " 'market',\n",
       " 'normal']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wordlist if len(w) >= 6\n",
    " and obligatory in w\n",
    " and nltk.FreqDist(w) <= puzzle_letters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([w for w in wordlist if len(w) >= 6\n",
    " and obligatory in w\n",
    " and nltk.FreqDist(w) <= puzzle_letters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
